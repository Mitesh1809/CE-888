{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NuralN_W.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mitesh1809/CE-888/blob/main/NuralN_W.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk9UnlEFcdeO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2pvDtincdeP",
        "outputId": "44368451-cb0a-4569-e58c-91cf4097700d"
      },
      "source": [
        "j = loadmat('WLDataAll.mat')\n",
        "j"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__globals__': [],\n",
              " '__header__': b'MATLAB 5.0 MAT-file, Platform: MACI64, Created on: Tue Jun  1 17:11:20 2021',\n",
              " '__version__': '1.0',\n",
              " 'data': array([[[ 4.8829541e+00,  9.8011837e+00, -6.1279667e+01, ...,\n",
              "          -2.3868773e+01,  1.0183847e+01,  6.5834889e+00],\n",
              "         [ 1.5645766e+01,  9.2562323e+00, -5.9352314e+01, ...,\n",
              "           6.3903937e+00, -3.4080923e-01,  7.2190175e+00],\n",
              "         [ 1.8576738e+01,  9.6379747e+00, -5.8535995e+01, ...,\n",
              "           3.4576672e+01, -3.2299006e+00,  4.3821239e-01],\n",
              "         ...,\n",
              "         [ 1.3261520e+01, -4.5882652e+01,  1.3235929e+01, ...,\n",
              "           1.9744860e+01, -1.1103893e+01,  5.8311663e+00],\n",
              "         [ 1.2880102e+01, -5.4907242e+01,  1.1796134e+01, ...,\n",
              "           2.2629681e+01, -7.8801956e+00,  9.1314917e+00],\n",
              "         [ 1.1365375e+01, -6.0526150e+01,  8.0718441e+00, ...,\n",
              "           1.9972019e+01, -9.1800272e-02,  2.4537776e+00]],\n",
              " \n",
              "        [[ 6.2141876e+00,  2.3298359e+01, -4.9112263e+01, ...,\n",
              "          -2.7136732e+01,  1.3108792e+01, -1.0402801e-02],\n",
              "         [ 2.0816244e+01,  2.2637253e+01, -4.7099533e+01, ...,\n",
              "           2.6988206e+00,  1.7181083e+00,  4.6453357e-01],\n",
              "         [ 2.5134890e+01,  2.2752033e+01, -4.6335308e+01, ...,\n",
              "           3.0565788e+01, -2.0004427e+00, -5.3312268e+00],\n",
              "         ...,\n",
              "         [ 2.5610659e+01, -3.6884819e+01,  9.5531950e+00, ...,\n",
              "           2.1718262e+01, -1.5028214e+01, -1.4782733e+00],\n",
              "         [ 2.6118378e+01, -4.4797615e+01,  8.6757174e+00, ...,\n",
              "           2.5414093e+01, -1.1935817e+01,  1.6412252e+00],\n",
              "         [ 2.4887039e+01, -4.9106499e+01,  5.2992163e+00, ...,\n",
              "           2.3196951e+01, -5.4231153e+00, -2.0184553e+00]],\n",
              " \n",
              "        [[ 5.8859887e+00,  2.4068096e+01, -1.8423073e+01, ...,\n",
              "          -3.5179005e+01,  1.5467652e+01, -4.1439157e+00],\n",
              "         [ 1.9027197e+01,  2.3788452e+01, -1.5515123e+01, ...,\n",
              "          -6.7933874e+00,  2.2526824e+00, -4.4970832e+00],\n",
              "         [ 2.3775873e+01,  2.4057838e+01, -1.4121702e+01, ...,\n",
              "           1.9801043e+01, -2.4991517e+00, -1.0090138e+01],\n",
              "         ...,\n",
              "         [ 2.3491199e+01, -1.3352211e+01,  1.9008224e+00, ...,\n",
              "           2.5398451e+01, -1.7371178e+01,  8.0388889e+00],\n",
              "         [ 2.4977736e+01, -1.8470139e+01,  1.7854822e+00, ...,\n",
              "           2.9940369e+01, -1.3818170e+01,  1.0659407e+01],\n",
              "         [ 2.4850731e+01, -2.0150917e+01, -6.5614241e-01, ...,\n",
              "           2.7205744e+01, -8.1378860e+00,  3.8657103e+00]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-1.1129264e+01,  6.2195497e+00, -1.3618125e+01, ...,\n",
              "          -5.0421665e+01, -5.1712543e+01, -1.2392020e+02],\n",
              "         [-3.5368681e+00,  5.9831185e+00, -6.9863501e+00, ...,\n",
              "          -1.8064293e+02,  3.7310215e+01, -6.8432800e+01],\n",
              "         [ 1.1712424e+00,  6.4098282e+00, -4.3152876e+00, ...,\n",
              "          -2.1445430e+02,  1.2648257e+02, -2.2241018e+01],\n",
              "         ...,\n",
              "         [ 8.0015574e+00, -1.3973220e+01,  7.4678802e+00, ...,\n",
              "           1.7170826e+01, -7.1101608e+01, -1.4201433e+02],\n",
              "         [ 8.2283087e+00, -1.9739189e+01,  7.2618527e+00, ...,\n",
              "          -4.1911236e+01, -1.4035114e+02, -1.3405362e+02],\n",
              "         [ 7.3389955e+00, -1.9394279e+01,  4.2824917e+00, ...,\n",
              "          -8.1219833e+01, -1.5925308e+02, -6.4565331e+01]],\n",
              " \n",
              "        [[ 1.1400555e+00,  2.9005888e+00, -2.3208757e+01, ...,\n",
              "           2.4991800e+01, -1.1886749e+00, -7.9105883e+00],\n",
              "         [ 6.0259323e+00,  3.9205053e+00, -1.7370226e+01, ...,\n",
              "           3.1124510e+01, -1.1514045e+01, -9.3741732e+00],\n",
              "         [ 7.5555024e+00,  4.4709024e+00, -1.4420144e+01, ...,\n",
              "           2.7311718e+01, -6.6273885e+00, -6.7305050e+00],\n",
              "         ...,\n",
              "         [-3.7986715e+00, -1.9970905e+01,  5.1485906e+00, ...,\n",
              "           1.6996380e+01, -7.5222737e-01, -5.1404536e-01],\n",
              "         [-1.3442979e+00, -2.5822805e+01,  1.8926101e+00, ...,\n",
              "           2.3147314e+01,  9.8062831e-01,  6.1114502e+00],\n",
              "         [ 1.1654859e+00, -2.7115149e+01, -1.9103953e+00, ...,\n",
              "           1.5229993e+01, -2.6415169e+00,  7.5060105e+00]],\n",
              " \n",
              "        [[-3.7260101e+00,  7.3183618e+00, -1.1189030e+01, ...,\n",
              "           1.9069122e+01, -5.6609602e+00, -2.3171125e+01],\n",
              "         [ 3.1745725e+00,  7.3386874e+00, -2.0818734e+00, ...,\n",
              "          -1.4325197e+01,  1.4303930e+01,  7.9576530e+00],\n",
              "         [ 5.0469308e+00,  9.4243946e+00, -2.2351679e-01, ...,\n",
              "          -2.6433064e+01,  3.5627422e+01,  1.7323019e+01],\n",
              "         ...,\n",
              "         [ 5.6844120e+00, -1.6980202e+01,  5.5858431e+00, ...,\n",
              "           4.0457020e+00, -2.2411016e+01, -3.8190929e+01],\n",
              "         [ 8.2543430e+00, -2.3248888e+01,  4.2881260e+00, ...,\n",
              "          -9.4144831e+00, -5.0788956e+01, -4.0038433e+01],\n",
              "         [ 8.4466515e+00, -2.0668167e+01, -1.5813452e+00, ...,\n",
              "          -1.4594034e+01, -5.1202698e+01, -1.8992659e+01]]], dtype=float32),\n",
              " 'label': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "         2, 2, 2, 2, 2, 2, 2, 2]], dtype=uint8)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "razlqPXIcdeR"
      },
      "source": [
        "x = j['data']\n",
        "y = j['label']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3aftBqOcdeS",
        "outputId": "1d34f64f-0ab0-45b9-b7c6-544264499b7a"
      },
      "source": [
        "x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 4.8829541e+00,  9.8011837e+00, -6.1279667e+01, ...,\n",
              "         -2.3868773e+01,  1.0183847e+01,  6.5834889e+00],\n",
              "        [ 1.5645766e+01,  9.2562323e+00, -5.9352314e+01, ...,\n",
              "          6.3903937e+00, -3.4080923e-01,  7.2190175e+00],\n",
              "        [ 1.8576738e+01,  9.6379747e+00, -5.8535995e+01, ...,\n",
              "          3.4576672e+01, -3.2299006e+00,  4.3821239e-01],\n",
              "        ...,\n",
              "        [ 1.3261520e+01, -4.5882652e+01,  1.3235929e+01, ...,\n",
              "          1.9744860e+01, -1.1103893e+01,  5.8311663e+00],\n",
              "        [ 1.2880102e+01, -5.4907242e+01,  1.1796134e+01, ...,\n",
              "          2.2629681e+01, -7.8801956e+00,  9.1314917e+00],\n",
              "        [ 1.1365375e+01, -6.0526150e+01,  8.0718441e+00, ...,\n",
              "          1.9972019e+01, -9.1800272e-02,  2.4537776e+00]],\n",
              "\n",
              "       [[ 6.2141876e+00,  2.3298359e+01, -4.9112263e+01, ...,\n",
              "         -2.7136732e+01,  1.3108792e+01, -1.0402801e-02],\n",
              "        [ 2.0816244e+01,  2.2637253e+01, -4.7099533e+01, ...,\n",
              "          2.6988206e+00,  1.7181083e+00,  4.6453357e-01],\n",
              "        [ 2.5134890e+01,  2.2752033e+01, -4.6335308e+01, ...,\n",
              "          3.0565788e+01, -2.0004427e+00, -5.3312268e+00],\n",
              "        ...,\n",
              "        [ 2.5610659e+01, -3.6884819e+01,  9.5531950e+00, ...,\n",
              "          2.1718262e+01, -1.5028214e+01, -1.4782733e+00],\n",
              "        [ 2.6118378e+01, -4.4797615e+01,  8.6757174e+00, ...,\n",
              "          2.5414093e+01, -1.1935817e+01,  1.6412252e+00],\n",
              "        [ 2.4887039e+01, -4.9106499e+01,  5.2992163e+00, ...,\n",
              "          2.3196951e+01, -5.4231153e+00, -2.0184553e+00]],\n",
              "\n",
              "       [[ 5.8859887e+00,  2.4068096e+01, -1.8423073e+01, ...,\n",
              "         -3.5179005e+01,  1.5467652e+01, -4.1439157e+00],\n",
              "        [ 1.9027197e+01,  2.3788452e+01, -1.5515123e+01, ...,\n",
              "         -6.7933874e+00,  2.2526824e+00, -4.4970832e+00],\n",
              "        [ 2.3775873e+01,  2.4057838e+01, -1.4121702e+01, ...,\n",
              "          1.9801043e+01, -2.4991517e+00, -1.0090138e+01],\n",
              "        ...,\n",
              "        [ 2.3491199e+01, -1.3352211e+01,  1.9008224e+00, ...,\n",
              "          2.5398451e+01, -1.7371178e+01,  8.0388889e+00],\n",
              "        [ 2.4977736e+01, -1.8470139e+01,  1.7854822e+00, ...,\n",
              "          2.9940369e+01, -1.3818170e+01,  1.0659407e+01],\n",
              "        [ 2.4850731e+01, -2.0150917e+01, -6.5614241e-01, ...,\n",
              "          2.7205744e+01, -8.1378860e+00,  3.8657103e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.1129264e+01,  6.2195497e+00, -1.3618125e+01, ...,\n",
              "         -5.0421665e+01, -5.1712543e+01, -1.2392020e+02],\n",
              "        [-3.5368681e+00,  5.9831185e+00, -6.9863501e+00, ...,\n",
              "         -1.8064293e+02,  3.7310215e+01, -6.8432800e+01],\n",
              "        [ 1.1712424e+00,  6.4098282e+00, -4.3152876e+00, ...,\n",
              "         -2.1445430e+02,  1.2648257e+02, -2.2241018e+01],\n",
              "        ...,\n",
              "        [ 8.0015574e+00, -1.3973220e+01,  7.4678802e+00, ...,\n",
              "          1.7170826e+01, -7.1101608e+01, -1.4201433e+02],\n",
              "        [ 8.2283087e+00, -1.9739189e+01,  7.2618527e+00, ...,\n",
              "         -4.1911236e+01, -1.4035114e+02, -1.3405362e+02],\n",
              "        [ 7.3389955e+00, -1.9394279e+01,  4.2824917e+00, ...,\n",
              "         -8.1219833e+01, -1.5925308e+02, -6.4565331e+01]],\n",
              "\n",
              "       [[ 1.1400555e+00,  2.9005888e+00, -2.3208757e+01, ...,\n",
              "          2.4991800e+01, -1.1886749e+00, -7.9105883e+00],\n",
              "        [ 6.0259323e+00,  3.9205053e+00, -1.7370226e+01, ...,\n",
              "          3.1124510e+01, -1.1514045e+01, -9.3741732e+00],\n",
              "        [ 7.5555024e+00,  4.4709024e+00, -1.4420144e+01, ...,\n",
              "          2.7311718e+01, -6.6273885e+00, -6.7305050e+00],\n",
              "        ...,\n",
              "        [-3.7986715e+00, -1.9970905e+01,  5.1485906e+00, ...,\n",
              "          1.6996380e+01, -7.5222737e-01, -5.1404536e-01],\n",
              "        [-1.3442979e+00, -2.5822805e+01,  1.8926101e+00, ...,\n",
              "          2.3147314e+01,  9.8062831e-01,  6.1114502e+00],\n",
              "        [ 1.1654859e+00, -2.7115149e+01, -1.9103953e+00, ...,\n",
              "          1.5229993e+01, -2.6415169e+00,  7.5060105e+00]],\n",
              "\n",
              "       [[-3.7260101e+00,  7.3183618e+00, -1.1189030e+01, ...,\n",
              "          1.9069122e+01, -5.6609602e+00, -2.3171125e+01],\n",
              "        [ 3.1745725e+00,  7.3386874e+00, -2.0818734e+00, ...,\n",
              "         -1.4325197e+01,  1.4303930e+01,  7.9576530e+00],\n",
              "        [ 5.0469308e+00,  9.4243946e+00, -2.2351679e-01, ...,\n",
              "         -2.6433064e+01,  3.5627422e+01,  1.7323019e+01],\n",
              "        ...,\n",
              "        [ 5.6844120e+00, -1.6980202e+01,  5.5858431e+00, ...,\n",
              "          4.0457020e+00, -2.2411016e+01, -3.8190929e+01],\n",
              "        [ 8.2543430e+00, -2.3248888e+01,  4.2881260e+00, ...,\n",
              "         -9.4144831e+00, -5.0788956e+01, -4.0038433e+01],\n",
              "        [ 8.4466515e+00, -2.0668167e+01, -1.5813452e+00, ...,\n",
              "         -1.4594034e+01, -5.1202698e+01, -1.8992659e+01]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbRBp5qPcdeT",
        "outputId": "f10cadc3-5c37-493a-a126-0325525df3f2"
      },
      "source": [
        "y"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJB-l63mcdeT"
      },
      "source": [
        "y = y-1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNhcAg14cdeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e7e6d3-80c2-4c98-eb43-5ffa1f1cfc0d"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((62, 512, 360), (1, 360))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stgbYeDucdeU",
        "outputId": "5fd2657e-3522-4895-dbc2-34d588bd8597"
      },
      "source": [
        "x = x.T\n",
        "y = y.T\n",
        "x.shape, y.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((360, 512, 62), (360, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcUk8xtNcdeV"
      },
      "source": [
        "x = x.reshape(x.shape[0], x.shape[1]*x.shape[2])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLF-g8QtcdeW",
        "outputId": "57694aab-098b-44d0-b5d3-da90853bc2df"
      },
      "source": [
        "x"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.8829541e+00,  6.2141876e+00,  5.8859887e+00, ...,\n",
              "         7.3389955e+00,  1.1654859e+00,  8.4466515e+00],\n",
              "       [ 9.8011837e+00,  2.3298359e+01,  2.4068096e+01, ...,\n",
              "        -1.9394279e+01, -2.7115149e+01, -2.0668167e+01],\n",
              "       [-6.1279667e+01, -4.9112263e+01, -1.8423073e+01, ...,\n",
              "         4.2824917e+00, -1.9103953e+00, -1.5813452e+00],\n",
              "       ...,\n",
              "       [-2.3868773e+01, -2.7136732e+01, -3.5179005e+01, ...,\n",
              "        -8.1219833e+01,  1.5229993e+01, -1.4594034e+01],\n",
              "       [ 1.0183847e+01,  1.3108792e+01,  1.5467652e+01, ...,\n",
              "        -1.5925308e+02, -2.6415169e+00, -5.1202698e+01],\n",
              "       [ 6.5834889e+00, -1.0402801e-02, -4.1439157e+00, ...,\n",
              "        -6.4565331e+01,  7.5060105e+00, -1.8992659e+01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvUqBgBTRMf"
      },
      "source": [
        "def initialize_parameters(n_in, n_out):\n",
        "    \n",
        "    params = dict() \n",
        "    params['W'] = np.random.randn(n_out, n_in) *0.01\n",
        "    params['b'] = np.zeros((n_out, 1))\n",
        "\n",
        "    return params\n",
        "\n",
        "class LinearLayer:\n",
        "    def __init__(self, input_shape, n_out):        \n",
        "        self.m = input_shape[1]\n",
        "        self.params = initialize_parameters(input_shape[0], n_out)\n",
        "        self.Z = np.zeros((self.params['W'].shape[0], input_shape[1]))\n",
        "\n",
        "    def forward(self, A_prev):\n",
        "        \n",
        "        self.A_prev = A_prev \n",
        "        self.Z = np.dot(self.params['W'], self.A_prev) + self.params['b'] \n",
        "\n",
        "    def backward(self, upstream_grad):\n",
        "        self.dW = np.dot(upstream_grad, self.A_prev.T)\n",
        "        self.db = np.sum(upstream_grad, axis=1, keepdims=True)\n",
        "        self.dA_prev = np.dot(self.params['W'].T, upstream_grad)\n",
        "\n",
        "    def update_params(self, learning_rate=0.1):\n",
        "        self.params['W'] = self.params['W'] - learning_rate * self.dW \n",
        "        self.params['b'] = self.params['b'] - learning_rate * self.db"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp7tYT00TT4O"
      },
      "source": [
        "class SigmoidLayer:\n",
        "    \n",
        "    def __init__(self, shape):\n",
        "        self.A = np.zeros(shape) \n",
        "\n",
        "    def forward(self, Z):\n",
        "        self.A = 1 / (1 + np.exp(-Z))\n",
        "        \n",
        "    def backward(self, upstream_grad):\n",
        "        self.dZ = upstream_grad * self.A*(1-self.A)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvzYped8TYbC"
      },
      "source": [
        "def compute_stable_bce_cost(Y, Z):\n",
        "  m = Y.shape[1]\n",
        "  cost = (1/m) * np.sum(np.maximum(Z, 0) - Z*Y + np.log(1+ np.exp(- np.abs(Z))))\n",
        "  dZ_last = (1/m) * ((1/(1+np.exp(- Z))) - Y)\n",
        "  return cost, dZ_last"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7XBPi6WTbXx"
      },
      "source": [
        "def compute_keras_like_bce_cost(Y, P_hat, from_logits=False):\n",
        "    if from_logits:\n",
        "        return compute_stable_bce_cost(Y, Z=P_hat)\n",
        "    else:\n",
        "        EPSILON = 1e-07\n",
        "        P_MAX = 1- EPSILON \n",
        "\n",
        "        P_hat = np.clip(P_hat, a_min=EPSILON, a_max=P_MAX)\n",
        "        Z = np.log(P_hat/(1-P_hat))\n",
        "        return compute_stable_bce_cost(Y, Z)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUgOzKHNTeOX"
      },
      "source": [
        "def predict(X, Y, Zs, As, thresh=0.5):\n",
        "    m = X.shape[1]\n",
        "    n = len(Zs)  # number of layers in the neural network\n",
        "    p = np.zeros((1, m))\n",
        "\n",
        "    # Forward propagation\n",
        "    Zs[0].forward(X)\n",
        "    As[0].forward(Zs[0].Z)\n",
        "    for i in range(1, n):\n",
        "        Zs[i].forward(As[i-1].A)\n",
        "        As[i].forward(Zs[i].Z)\n",
        "    probas = As[n-1].A\n",
        "\n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0, i] >= thresh:  # 0.5  the default threshold\n",
        "            p[0, i] = 1\n",
        "        else:\n",
        "            p[0, i] = 0\n",
        "\n",
        "    accuracy = np.sum((p == Y) / m)\n",
        "\n",
        "    return p, probas, accuracy*100"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q4I1OPiTlXT",
        "outputId": "8a869f1b-2781-4a98-ed93-aabe887547af"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "accuracy = []\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "for train_index, test_index in kf.split(x):\n",
        "    X_train, X_test = x[train_index], x[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    learning_rate = 1\n",
        "    number_of_epochs = 30\n",
        "\n",
        "    np.random.seed(0)\n",
        "    Z1 = LinearLayer(input_shape=X_train.T.shape, n_out=1)\n",
        "    A1 = SigmoidLayer(Z1.Z.shape)\n",
        "\n",
        "    costs = [] \n",
        "    for epoch in range(number_of_epochs):\n",
        "      Z1.forward(X_train.T)\n",
        "      A1.forward(Z1.Z)\n",
        "      cost, dZ1 = compute_stable_bce_cost(y_train.T, Z1.Z)\n",
        "      if (epoch % 2) == 0 or epoch == number_of_epochs - 1:\n",
        "        print(\"Cost at epoch#{}: {}\".format(epoch, cost))\n",
        "        costs.append(cost)\n",
        "        Z1.backward(dZ1)\n",
        "        Z1.update_params(learning_rate=learning_rate)\n",
        "\n",
        "    predicted_outputs, p_hat, acc = predict(X=X_test.T, Y=y_test.T, \n",
        "                                                Zs=[Z1], As=[A1], thresh=0.5)\n",
        "    accuracy.append(acc)\n",
        "    print(\"\\nThe accuracy of the model is: {}%\".format(acc))\n",
        "\n",
        "print(f'average accuracy: {np.mean(accuracy)}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost at epoch#0: 14.45943267461816\n",
            "Cost at epoch#2: 26310.081669807245\n",
            "Cost at epoch#4: 11227.509671544274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in exp\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cost at epoch#6: 8735.146365628047\n",
            "Cost at epoch#8: 8006.10009600604\n",
            "Cost at epoch#10: 6230.751727960541\n",
            "Cost at epoch#12: 3360.9439262256715\n",
            "Cost at epoch#14: 1351.865098957082\n",
            "Cost at epoch#16: 913.3804889852577\n",
            "Cost at epoch#18: 510.34027975205225\n",
            "Cost at epoch#20: 373.72416493920014\n",
            "Cost at epoch#22: 962.1698543490902\n",
            "Cost at epoch#24: 695.9969012143167\n",
            "Cost at epoch#26: 312.7753431672738\n",
            "Cost at epoch#28: 22.181377800936236\n",
            "Cost at epoch#29: 3.8030119255835437\n",
            "\n",
            "The accuracy of the model is: 38.88888888888889%\n",
            "Cost at epoch#0: 13.092687900761767\n",
            "Cost at epoch#2: 26991.394981977763\n",
            "Cost at epoch#4: 8511.100766018588\n",
            "Cost at epoch#6: 11328.274937972128\n",
            "Cost at epoch#8: 6906.098752364958\n",
            "Cost at epoch#10: 7821.235972052137\n",
            "Cost at epoch#12: 4764.808323370275\n",
            "Cost at epoch#14: 4448.124583072122\n",
            "Cost at epoch#16: 4476.282664921823\n",
            "Cost at epoch#18: 2553.356129513303\n",
            "Cost at epoch#20: 3398.437267241679\n",
            "Cost at epoch#22: 1652.2190133683607\n",
            "Cost at epoch#24: 1345.3436552914272\n",
            "Cost at epoch#26: 879.86258701487\n",
            "Cost at epoch#28: 651.1140028300488\n",
            "Cost at epoch#29: 206.44929242044304\n",
            "\n",
            "The accuracy of the model is: 48.61111111111111%\n",
            "Cost at epoch#0: 13.218425051629065\n",
            "Cost at epoch#2: 26880.247784863685\n",
            "Cost at epoch#4: 9620.727744900856\n",
            "Cost at epoch#6: 8924.752099094227\n",
            "Cost at epoch#8: 7268.898135518988\n",
            "Cost at epoch#10: 7789.647125286367\n",
            "Cost at epoch#12: 4809.853869221194\n",
            "Cost at epoch#14: 5567.31817615245\n",
            "Cost at epoch#16: 2915.529162124035\n",
            "Cost at epoch#18: 3850.7511739960332\n",
            "Cost at epoch#20: 3401.165959988568\n",
            "Cost at epoch#22: 2143.746664866518\n",
            "Cost at epoch#24: 1088.3510229155202\n",
            "Cost at epoch#26: 1052.8324393116707\n",
            "Cost at epoch#28: 407.0273106018876\n",
            "Cost at epoch#29: 39.71802219430757\n",
            "\n",
            "The accuracy of the model is: 48.611111111111114%\n",
            "Cost at epoch#0: 15.027107423371552\n",
            "Cost at epoch#2: 30621.590420181656\n",
            "Cost at epoch#4: 11915.934884328517\n",
            "Cost at epoch#6: 7887.531794365084\n",
            "Cost at epoch#8: 8849.90056997938\n",
            "Cost at epoch#10: 6516.455357304063\n",
            "Cost at epoch#12: 4749.523440029275\n",
            "Cost at epoch#14: 1536.9091495512387\n",
            "Cost at epoch#16: 1236.8509533477732\n",
            "Cost at epoch#18: 488.08806131594366\n",
            "Cost at epoch#20: 158.35204560340762\n",
            "Cost at epoch#22: 57.179773984225164\n",
            "Cost at epoch#24: 21.344200084235855\n",
            "Cost at epoch#26: 3.1719967698036027\n",
            "Cost at epoch#28: 1.693602209629221\n",
            "Cost at epoch#29: 12.930738940623174\n",
            "\n",
            "The accuracy of the model is: 43.05555555555556%\n",
            "Cost at epoch#0: 12.85372308011028\n",
            "Cost at epoch#2: 28452.654549960844\n",
            "Cost at epoch#4: 7914.524428555056\n",
            "Cost at epoch#6: 9633.109200689338\n",
            "Cost at epoch#8: 8914.75856744286\n",
            "Cost at epoch#10: 7664.716071623424\n",
            "Cost at epoch#12: 5495.766321307456\n",
            "Cost at epoch#14: 4364.465230207868\n",
            "Cost at epoch#16: 3950.5289979829554\n",
            "Cost at epoch#18: 2409.857644446079\n",
            "Cost at epoch#20: 2219.067237687553\n",
            "Cost at epoch#22: 1446.987091994147\n",
            "Cost at epoch#24: 1367.4866428119303\n",
            "Cost at epoch#26: 856.3190553852752\n",
            "Cost at epoch#28: 748.6761565665056\n",
            "Cost at epoch#29: 474.5119652876126\n",
            "\n",
            "The accuracy of the model is: 48.61111111111111%\n",
            "average accuracy: 45.55555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eit-7YY_cdea",
        "outputId": "bedff9d5-be37-41ec-d624-f0d2fb9b2850"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "kfold = KFold(n_splits=6)\n",
        "fold_no = 1\n",
        "acc_per_fold = list()\n",
        "loss_per_fold = list()\n",
        "\n",
        "for train, test in kfold.split(x):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.7))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "\n",
        "    history = model.fit(x_train, y_train,\n",
        "              batch_size=20,\n",
        "              epochs=10)\n",
        "\n",
        "    # Generate generalization metrics\n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 22s 24ms/step - loss: 36.8221 - accuracy: 0.6191\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 67.9084 - accuracy: 0.6114\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 41.4823 - accuracy: 0.6277\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 71.2938 - accuracy: 0.5881\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 68.5464 - accuracy: 0.6230\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 60.3201 - accuracy: 0.6216\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 44.3339 - accuracy: 0.6114\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 57.4328 - accuracy: 0.5881\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 71.6127 - accuracy: 0.6047\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 47.2165 - accuracy: 0.6439\n",
            "Score for fold 1: loss of 53.92277145385742; accuracy of 0.0%\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 23ms/step - loss: 46.3496 - accuracy: 0.4257\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 48.6789 - accuracy: 0.3876\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 52.2444 - accuracy: 0.4052\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 47.5813 - accuracy: 0.3589\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 63.4526 - accuracy: 0.4277\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 63.1335 - accuracy: 0.3887\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 49.6336 - accuracy: 0.4381\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 64.0418 - accuracy: 0.4214\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 49.6594 - accuracy: 0.3910\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 61.0719 - accuracy: 0.3940\n",
            "Score for fold 2: loss of 129.5145721435547; accuracy of 100.0%\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 23ms/step - loss: 29.4743 - accuracy: 0.5946\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 55.3306 - accuracy: 0.5824\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 41.2399 - accuracy: 0.6287\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 51.8100 - accuracy: 0.5691\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 37.1966 - accuracy: 0.6374\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 38.7325 - accuracy: 0.5997\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 27.7716 - accuracy: 0.6142\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 37.7079 - accuracy: 0.5828\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 44.9376 - accuracy: 0.6363\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 28.6047 - accuracy: 0.6015\n",
            "Score for fold 3: loss of 284.6162414550781; accuracy of 0.0%\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 24ms/step - loss: 38.1607 - accuracy: 0.4303\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 52.9442 - accuracy: 0.3773\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 54.4576 - accuracy: 0.3974\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 54.0019 - accuracy: 0.3941\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 52.0844 - accuracy: 0.3820\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 68.7438 - accuracy: 0.3732\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 58.8789 - accuracy: 0.3477\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 64.7565 - accuracy: 0.4142\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 41.2806 - accuracy: 0.4052\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 84.6035 - accuracy: 0.3979\n",
            "Score for fold 4: loss of 48.627662658691406; accuracy of 100.0%\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 23ms/step - loss: 38.5273 - accuracy: 0.5694\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 46.9798 - accuracy: 0.6300\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 52.2379 - accuracy: 0.5710\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 53.8743 - accuracy: 0.6012\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 44.9475 - accuracy: 0.6127\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 39.3911 - accuracy: 0.5921\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 48.4017 - accuracy: 0.5804\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 54.1416 - accuracy: 0.6342\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 44.0745 - accuracy: 0.5929\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 35.5959 - accuracy: 0.5953\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd7c1ee6b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 5: loss of 71.040283203125; accuracy of 0.0%\n",
            "Training for fold 6 ...\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 2s 24ms/step - loss: 36.7859 - accuracy: 0.4171\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 50.1651 - accuracy: 0.4072\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 47.6275 - accuracy: 0.4224\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 29.8082 - accuracy: 0.3905\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 33.3630 - accuracy: 0.4077\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 44.1213 - accuracy: 0.3984\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 40.1251 - accuracy: 0.4272\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 26.1974 - accuracy: 0.3925\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 31.2723 - accuracy: 0.4188\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 37.6920 - accuracy: 0.3987\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd7c1e0c440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 6: loss of 305.1455383300781; accuracy of 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDB_v4TLoFD1"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}